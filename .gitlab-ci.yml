image:
  name: python:3.7
  entrypoint:
    - '/usr/bin/env'
    - 'PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'

variables:
  JOB_RUNS: "3"

cache:
  paths:
    - .env

before_script:
  - apt-get update -qy
  - apt-get install curl
  - curl -sL https://deb.nodesource.com/setup_12.x | bash -
  - apt-get install nodejs
  - npm install -g aws-cdk
  - apt-get install -y python-dev python-pip
  - mkdir -p ~/.aws ./.env
  - echo $AWS_SERVICE_ACCOUNT | base64 -d > ./.aws/config
  - python -m venv .env && source .env/bin/activeate
  - python -m pip install awscli boto3
  - python -m pip install -r requirements.txt


stages:
  - validate
  - build
  - test
  - deploy
  - run
  - decommution

validate:
  stage: validate
  script:
    - cdk version

plan:
  stage: build
  script:
    - source .env/bin/activate
    - cdk synth -j > cfn.json
  artifacts:
    name: validate
    paths:
      - cfn.json
    reports:
      junit: cfn.json


# Separate apply job for manual launching Terraform as it can be destructive
# action.
apply:
  stage: deploy
  script:
    - cdk deploy -O outputs.json
  artifacts:
    name: production
    paths:
      - outputs.json
    reports:
      junit: outputs.json

  dependencies:
    - plan
  when: manual
  only:
    - develop

run:
  stage: run
  script:
    - aws stepfunctions start-execution --state-machine-arn $(cat outputs.json | jq -r ".startup.statemachinearn") --name "ci-test-3" --input "{\"job_runs\":\"$JOB_RUNS\"}"

  dependencies:
    - appl

destroy:
  stage: decommution
  script:
    - cdk destroy
  dependencies:
    - plan
  when: manual
  only:
    - develop

